import { Mensagem } from '../types/conversa';
import openai from '../config/openai';

// Cache simples para manter hist√≥rico por n√∫mero (independente do banco)
const conversationHistory: { [key: string]: any[] } = {};

export async function gerarPromptCerebro(
  historico: Mensagem[],
  mensagemCliente: string,
  numeroCliente?: string
): Promise<string | null> {
  try {
    const numero = numeroCliente || 'default';
    
    // Adicionar mensagem atual ao hist√≥rico
    if (!conversationHistory[numero]) {
      conversationHistory[numero] = [];
    }
    
    conversationHistory[numero].push({
      autor: 'cliente',
      texto: mensagemCliente,
      timestamp: new Date().toISOString()
    });

    // Manter apenas √∫ltimas 20 mensagens para contexto
    if (conversationHistory[numero].length > 20) {
      conversationHistory[numero] = conversationHistory[numero].slice(-20);
    }

    // Formatar hist√≥rico simples para a IA
    const historicoFormatado = conversationHistory[numero]
      .map((msg: { autor: string; texto: string }) => `${msg.autor}: ${msg.texto}`)
      .join('\n');

    // Prompt simples apenas com hist√≥rico
    const prompt = `Hist√≥rico da conversa:
${historicoFormatado}

Mensagem atual do cliente: ${mensagemCliente}

Responda de forma natural e amig√°vel, sempre focando em ajudar com d√≠vidas banc√°rias.`;

    console.log('üß† Hist√≥rico fornecido (primeiros 500 chars):', prompt.substring(0, 500) + '...');

    // Usar o Assistant ID espec√≠fico
    const assistantId = 'asst_rPvHoutBw01eSySqhtTK4Iv7';
    
    // Criar um novo thread para cada conversa
    const thread = await openai.beta.threads.create();
    
    // Adicionar mensagem ao thread
    await openai.beta.threads.messages.create(thread.id, {
      role: 'user',
      content: prompt
    });

    // Executar o assistente
    const run = await openai.beta.threads.runs.create(thread.id, {
      assistant_id: assistantId
    });

    // Aguardar conclus√£o
    let runStatus = await openai.beta.threads.runs.retrieve(thread.id, run.id);
    
    while (runStatus.status === 'in_progress' || runStatus.status === 'queued') {
      await new Promise(resolve => setTimeout(resolve, 1000));
      runStatus = await openai.beta.threads.runs.retrieve(thread.id, run.id);
    }

    if (runStatus.status === 'completed') {
      const messages = await openai.beta.threads.messages.list(thread.id);
      const lastMessage = messages.data[0];
      
      if (lastMessage && lastMessage.content[0].type === 'text') {
        const resposta = lastMessage.content[0].text.value;
        
        // Adicionar resposta da IA ao hist√≥rico
        conversationHistory[numero].push({
          autor: 'clara',
          texto: resposta,
          timestamp: new Date().toISOString()
        });
        
        console.log('ü§ñ Resposta da IA:', resposta);
        return resposta;
      } else {
        console.error('‚ùå Erro: IA n√£o retornou resposta v√°lida');
        return 'Ol√°! Como posso ajud√°-lo com suas d√≠vidas banc√°rias hoje?';
      }
    } else {
      console.error('‚ùå Erro: Run falhou com status:', runStatus.status);
      return 'Ol√°! Como posso ajud√°-lo com suas d√≠vidas banc√°rias hoje?';
    }

  } catch (error) {
    console.error('‚ùå Erro ao gerar resposta da IA:', error);
    
    // Fallback simples
    if (mensagemCliente.toLowerCase().includes('ol√°') || mensagemCliente.toLowerCase().includes('oi') || mensagemCliente.toLowerCase().includes('ola')) {
      return 'Ol√°! Seja bem-vindo √† Resoluty Consultoria! Meu nome √© Clara e estou aqui para te ajudar na redu√ß√£o das suas d√≠vidas banc√°rias. Como voc√™ se chama?';
    }
    
    return 'Ol√°! Como posso ajud√°-lo com suas d√≠vidas banc√°rias hoje?';
  }
}