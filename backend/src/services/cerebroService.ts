import { Mensagem } from '../types/conversa';
import openai from '../config/openai';

/**
 * Gera prompt para o c√©rebro da IA com o contexto da conversa
 */
export async function gerarPromptCerebro(
  historico: Mensagem[], 
  mensagemCliente: string
): Promise<string | null> {
  try {
    // Verificar se a API key est√° configurada
    if (!process.env.OPENAI_API_KEY) {
      console.error('‚ùå Erro: OPENAI_API_KEY n√£o est√° configurada');
      return null;
    }

    // Filtra mensagens muito curtas ou vazias
    const historicoFiltrado = historico.filter(msg => msg.texto && msg.texto.length > 2);
    
    // Filtra mensagens muito antigas (mant√©m apenas √∫ltimas 50 mensagens)
    const historicoLimitado = historicoFiltrado.slice(-50);
    
    // Formata o hist√≥rico com timestamps
    const historicoFormatado = historicoLimitado.map((msg) => {
      const timestamp = msg.timestamp ? new Date(msg.timestamp).toLocaleString('pt-BR') : 'Sem timestamp';
      return `[${timestamp}] ${msg.autor === 'usuario' ? 'Cliente' : 'Clara'}: ${msg.texto}`;
    }).join('\n');

    // Prompt simplificado apenas com contexto
    const prompt = `Leia a seguinte mensagem do Cliente: ${mensagemCliente}

Baseado na mensagem recebida e no hist√≥rico das mensagens, detecte a inten√ß√£o do cliente

Caso o Cliente tenha dito o valor total da divida, responda apenas o seguinte: "O Valor da Divida do Cliente √© de" e adicione o valor da Divida

Caso o Cliente tenha sugerido claramente um hor√°rio para Reuni√£o, responda apenas o seguinte: "Agendar Google Meet "

Caso o cliente tenha dito que recebe sal√°rio em conta responda apenas o seguinte: "Abrir para Atendente"

Caso n√£o seja nenhuma das inten√ß√µes citadas, apenas consulte o documento SCRIPT SDR PDE e mande a mensagem prevista, lembre se, mande somente a mensagem pronta, para que ela seja encaminhada diretamente para o cliente

=== HIST√ìRICO DA CONVERSA ===
${historicoFormatado}`;

    console.log('üß† Contexto fornecido (primeiros 500 chars):', prompt.substring(0, 500) + '...');

    // Criar um novo thread para cada conversa
    const thread = await openai.beta.threads.create();
    
    // Adicionar mensagem ao thread
    await openai.beta.threads.messages.create(thread.id, {
      role: 'user',
      content: prompt
    });

    // Executar o assistente com o ID espec√≠fico
    const run = await openai.beta.threads.runs.create(thread.id, {
      assistant_id: 'asst_rPvHoutBw01eSySqhtTK4Iv7'
    });

    // Aguardar conclus√£o
    let runStatus = await openai.beta.threads.runs.retrieve(thread.id, run.id);
    
    while (runStatus.status === 'in_progress' || runStatus.status === 'queued') {
      await new Promise(resolve => setTimeout(resolve, 1000));
      runStatus = await openai.beta.threads.runs.retrieve(thread.id, run.id);
    }

    if (runStatus.status === 'completed') {
      // Buscar a resposta
      const messages = await openai.beta.threads.messages.list(thread.id);
      const lastMessage = messages.data[0];
      
      if (lastMessage && lastMessage.content[0].type === 'text') {
        const aiResponse = lastMessage.content[0].text.value;
        console.log('ü§ñ Resposta da IA:', aiResponse);
        return aiResponse;
      } else {
        console.error('‚ùå Erro: IA n√£o retornou resposta v√°lida');
        return null;
      }
    } else {
      console.error('‚ùå Erro na execu√ß√£o da IA:', runStatus.status);
      return null;
    }

  } catch (error) {
    console.error('‚ùå Erro ao gerar resposta da IA:', error);
    
    // Fallback response para evitar quebra do sistema
    if (mensagemCliente.toLowerCase().includes('ol√°') || mensagemCliente.toLowerCase().includes('oi') || mensagemCliente.toLowerCase().includes('ola')) {
      return 'Ol√°! Como posso ajud√°-lo hoje?';
    }
    
    return 'Desculpe, n√£o consegui processar sua mensagem no momento. Um atendente ser√° direcionado para voc√™ em breve.';
  }
}